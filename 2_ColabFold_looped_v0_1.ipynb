{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yBrceuFbf3"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/sokrypton/ColabFold/main/.github/ColabFold_Marv_Logo_Small.png\" height=\"200\" align=\"right\" style=\"height:240px\">\n",
        "\n",
        "##ColabFold v1.5.5: AlphaFold2 using MMseqs2\n",
        "\n",
        "Easy to use protein structure and complex prediction using [AlphaFold2](https://www.nature.com/articles/s41586-021-03819-2) and [Alphafold2-multimer](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v1). Sequence alignments/templates are generated through [MMseqs2](mmseqs.com) and [HHsearch](https://github.com/soedinglab/hh-suite). For more details, see <a href=\"#Instructions\">bottom</a> of the notebook, checkout the [ColabFold GitHub](https://github.com/sokrypton/ColabFold) and read our manuscript.\n",
        "Old versions: [v1.4](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.4.0/AlphaFold2.ipynb), [v1.5.1](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.5.1/AlphaFold2.ipynb), [v1.5.2](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.5.2/AlphaFold2.ipynb), [v1.5.3-patch](https://colab.research.google.com/github/sokrypton/ColabFold/blob/56c72044c7d51a311ca99b953a71e552fdc042e1/AlphaFold2.ipynb)\n",
        "\n",
        "[Mirdita M, SchÃ¼tze K, Moriwaki Y, Heo L, Ovchinnikov S, Steinegger M. ColabFold: Making protein folding accessible to all.\n",
        "*Nature Methods*, 2022](https://www.nature.com/articles/s41592-022-01488-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDtikBdzvgKU"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnf5qPZVHl9x"
      },
      "source": [
        "**Single AlphaFold in Loop Prediction with Custom MSAs or MMSeq2**\n",
        "\n",
        "This Colab notebook automates the process of running AlphaFold predictions on multiple protein sequences using ColabFold. Main differences to the Batch version:\n",
        "\n",
        "*   Allows to variably set the number of seeds\n",
        "*   Allows custom MSAs. Jackhmmer can in certain cases outperform MMSeq2 and improve downstream multimer predictions\n",
        "\n",
        "Further:\n",
        "*   Save Results to Google Drive: Automatically upload prediction results to a specified folder in your Google Drive. Dont forget to set this for your GDrive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_asZ4feYTsu"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y pydrive\n",
        "!pip install pydrive2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bvG2ENfpd_dh"
      },
      "outputs": [],
      "source": [
        "#@title ALL\n",
        "!pip install biopython\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "import os\n",
        "import fileinput\n",
        "import os\n",
        "import shutil\n",
        "from Bio import SeqIO\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "result_directory = '/content/drive/MyDrive/Uni/Studium/PhD/LifeAct_Motiv_Projekt/Effectors/Results' #@param {type:\"string\"}\n",
        "fasta_directory = '/content/drive/MyDrive/Uni/Studium/PhD/LifeAct_Motiv_Projekt/Effectors/Fasta'  #@param {type:\"string\"}\n",
        "msa_directory = '/content/drive/MyDrive//Uni/Studium/PhD/LifeAct_Motiv_Projekt/Effectors/MSA'  #@param {type:\"string\"}\n",
        "template_directory = '' #@param {type:\"string\"}\n",
        "\n",
        "def get_folder_id_from_path(drive, path):\n",
        "    # Remove the local root path if present\n",
        "    local_root = '/content/drive/My Drive/'\n",
        "    if path.startswith(local_root):\n",
        "        path = path[len(local_root):]\n",
        "    elif path.startswith('/'):\n",
        "        path = path[1:]  # Remove leading slash if any\n",
        "\n",
        "    path_parts = path.strip('/').split('/')\n",
        "    folder_id = 'root'  # Start from the root of Google Drive\n",
        "\n",
        "    for part in path_parts:\n",
        "        # Search for the folder with this name in the current directory\n",
        "        query = f\"'{folder_id}' in parents and title='{part}' and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
        "        file_list = drive.ListFile({'q': query}).GetList()\n",
        "        if len(file_list) == 0:\n",
        "            # Folder doesn't exist; create it\n",
        "            folder_metadata = {\n",
        "                'title': part,\n",
        "                'parents': [{'id': folder_id}],\n",
        "                'mimeType': 'application/vnd.google-apps.folder'\n",
        "            }\n",
        "            folder = drive.CreateFile(folder_metadata)\n",
        "            folder.Upload()\n",
        "            folder_id = folder['id']\n",
        "            print(f\"Created folder '{part}' with ID: {folder_id}\")\n",
        "        else:\n",
        "            # Folder exists; use its ID\n",
        "            folder_id = file_list[0]['id']\n",
        "            print(f\"Found folder '{part}' with ID: {folder_id}\")\n",
        "    return folder_id\n",
        "\n",
        "\n",
        "def run_prediction(query_sequence, jobname):\n",
        "  from google.colab import files\n",
        "  import os\n",
        "  import re\n",
        "  import hashlib\n",
        "  import random\n",
        "  import time\n",
        "\n",
        "  from sys import version_info\n",
        "  python_version = f\"{version_info.major}.{version_info.minor}\"\n",
        "\n",
        "  def add_hash(x,y):\n",
        "    return x+\"_\"+hashlib.sha1(y.encode()).hexdigest()[:5]\n",
        "\n",
        "  # number of models to use\n",
        "  num_relax = 0 #@param [0, 1, 5] {type:\"raw\"}\n",
        "  #@markdown - specify how many of the top ranked structures to relax using amber\n",
        "  template_mode = \"none\" #@param [\"none\", \"pdb100\",\"custom\"]\n",
        "  #@markdown - `none` = no template information is used. `pdb100` = detect templates in pdb100 (see [notes](#pdb100)). `custom` - upload and search own templates (PDB or mmCIF format, see [notes](#custom_templates))\n",
        "  #@markdown ### MSA options (custom MSA upload, single sequence, pairing mode)\n",
        "  msa_mode = \"custom\" #@param [\"mmseqs2_uniref_env\", \"mmseqs2_uniref\",\"single_sequence\",\"custom\"]\n",
        "  pair_mode = \"unpaired_paired\" #@param [\"unpaired_paired\",\"paired\",\"unpaired\"] {type:\"string\"}\n",
        "  #@markdown - \"unpaired_paired\" = pair sequences from same species + unpaired MSA, \"unpaired\" = seperate MSA for each chain, \"paired\" - only use paired sequences.\n",
        "  use_amber = num_relax > 0\n",
        "\n",
        "  # remove whitespaces\n",
        "  query_sequence = \"\".join(query_sequence.split())\n",
        "\n",
        "  a3mname = \"\".join(jobname.split())\n",
        "  basejobname = \"\".join(jobname.split())\n",
        "  basejobname = re.sub(r'\\W+', '', basejobname)\n",
        "  jobname = add_hash(basejobname, query_sequence)\n",
        "\n",
        "  # check if directory with jobname exists\n",
        "  def check(folder):\n",
        "    if os.path.exists(folder):\n",
        "      return False\n",
        "    else:\n",
        "      return True\n",
        "  if not check(jobname):\n",
        "    n = 0\n",
        "    while not check(f\"{jobname}_{n}\"): n += 1\n",
        "    jobname = f\"{jobname}_{n}\"\n",
        "\n",
        "  # make directory to save results\n",
        "  os.makedirs(jobname, exist_ok=True)\n",
        "\n",
        "  # Determine queries_path based on msa_mode\n",
        "  if msa_mode == \"custom\":\n",
        "      # Use the provided MSA file\n",
        "      a3m_file = os.path.join(msa_directory, f\"c_{a3mname}.a3m\")\n",
        "      if not os.path.isfile(a3m_file):\n",
        "          print(f\"Error: {a3m_file} not found.\")\n",
        "          return False\n",
        "      else:\n",
        "          print(f\"Using provided MSA file: {a3m_file}\")\n",
        "      queries_path = a3m_file\n",
        "  else:\n",
        "      # Use MMSeqs2: create a CSV without the a3m_file column\n",
        "      queries_path = os.path.join(jobname, f\"{jobname}.csv\")\n",
        "      with open(queries_path, \"w\") as text_file:\n",
        "          # Only include id and sequence for MMSeqs2 modes\n",
        "          text_file.write(f\"id,sequence\\n{jobname},{query_sequence}\\n\")\n",
        "\n",
        "  if template_mode == \"pdb100\":\n",
        "    use_templates = True\n",
        "    custom_template_path = None\n",
        "  elif template_mode == \"custom\":\n",
        "    use_templates = True\n",
        "    custom_template_path = template_directory\n",
        "  else:\n",
        "    custom_template_path = None\n",
        "    use_templates = False\n",
        "\n",
        "  print(\"a3mname\",a3mname)\n",
        "  print(\"jobname\",jobname)\n",
        "  print(\"sequence\",query_sequence)\n",
        "  print(\"length\",len(query_sequence.replace(\":\",\"\")))\n",
        "\n",
        "\n",
        "  #@title Install dependencies\n",
        "\n",
        "  import os\n",
        "  USE_AMBER = use_amber\n",
        "  USE_TEMPLATES = use_templates\n",
        "  PYTHON_VERSION = python_version\n",
        "\n",
        "\n",
        "    #if not os.path.isfile(\"COLABFOLD_READY\"):\n",
        "    #print(\"installing colabfold...\")\n",
        "    #os.system(\"pip install -q --no-warn-conflicts 'colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold'\")\n",
        "    #os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\")\n",
        "    #os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\")\n",
        "    #os.system(\"touch COLABFOLD_READY\")\n",
        "\n",
        "\n",
        "  if not os.path.isfile(\"COLABFOLD_READY\"):\n",
        "    print(\"installing colabfold...\")\n",
        "    os.system(\"pip install -q --no-warn-conflicts 'colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold'\")\n",
        "    if os.environ.get('TPU_NAME', False) != False:\n",
        "      os.system(\"pip uninstall -y jax jaxlib\")\n",
        "      os.system(\"pip install --no-warn-conflicts --upgrade dm-haiku==0.0.10 'jax[cuda12_pip]'==0.3.25 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\")\n",
        "    os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\")\n",
        "    os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\")\n",
        "    # hack to fix TF crash\n",
        "    os.system(\"rm -f /usr/local/lib/python3.*/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so\")\n",
        "    os.system(\"touch COLABFOLD_READY\")\n",
        "\n",
        "\n",
        "  if USE_AMBER or USE_TEMPLATES:\n",
        "    if not os.path.isfile(\"CONDA_READY\"):\n",
        "      print(\"installing conda...\")\n",
        "      os.system(\"wget -qnc https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\")\n",
        "      os.system(\"bash Miniforge3-Linux-x86_64.sh -bfp /usr/local\")\n",
        "      os.system(\"mamba config --set auto_update_conda false\")\n",
        "      os.system(\"touch CONDA_READY\")\n",
        "\n",
        "  if USE_TEMPLATES and not os.path.isfile(\"HH_READY\") and USE_AMBER and not os.path.isfile(\"AMBER_READY\"):\n",
        "    print(\"installing hhsuite and amber...\")\n",
        "    os.system(f\"mamba install -y -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 openmm=7.7.0 python='{PYTHON_VERSION}' pdbfixer\")\n",
        "    os.system(\"touch HH_READY\")\n",
        "    os.system(\"touch AMBER_READY\")\n",
        "  else:\n",
        "    if USE_TEMPLATES and not os.path.isfile(\"HH_READY\"):\n",
        "      print(\"installing hhsuite...\")\n",
        "      os.system(f\"mamba install -y -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python='{PYTHON_VERSION}'\")\n",
        "      os.system(\"touch HH_READY\")\n",
        "    if USE_AMBER and not os.path.isfile(\"AMBER_READY\"):\n",
        "      print(\"installing amber...\")\n",
        "      os.system(f\"mamba install -y -c conda-forge openmm=7.7.0 python='{PYTHON_VERSION}' pdbfixer\")\n",
        "      os.system(\"touch AMBER_READY\")\n",
        "\n",
        "\n",
        "    # Save queries based on msa_mode\n",
        "    if msa_mode != \"custom\":\n",
        "        # For MMSeqs2 modes, ensure a3m_file is not set\n",
        "        print(\"Using MMSeqs2 for MSA generation.\")\n",
        "    else:\n",
        "        print(\"Using custom MSA.\")\n",
        "\n",
        "\n",
        "  #@markdown ### Advanced settings\n",
        "  model_type = \"alphafold2_multimer_v3\" #@param [\"auto\", \"alphafold2_ptm\", \"alphafold2_multimer_v1\", \"alphafold2_multimer_v2\", \"alphafold2_multimer_v3\", \"deepfold_v1\"]\n",
        "  #@markdown - if `auto` selected, will use `alphafold2_ptm` for monomer prediction and `alphafold2_multimer_v3` for complex prediction.\n",
        "  #@markdown Any of the mode_types can be used (regardless if input is monomer or complex).\n",
        "  num_recycles = \"3\" #@param [\"auto\", \"0\", \"1\", \"3\", \"6\", \"12\", \"24\", \"48\"]\n",
        "  #@markdown - if `auto` selected, will use `num_recycles=20` if `model_type=alphafold2_multimer_v3`, else `num_recycles=3` .\n",
        "  recycle_early_stop_tolerance = \"0.0\" #@param [\"auto\", \"0.0\", \"0.5\", \"1.0\"]\n",
        "  #@markdown - if `auto` selected, will use `tol=0.5` if `model_type=alphafold2_multimer_v3` else `tol=0.0`.\n",
        "  relax_max_iterations = 200 #@param [0, 200, 2000] {type:\"raw\"}\n",
        "  #@markdown - max amber relax iterations, `0` = unlimited (AlphaFold2 default, can take very long)\n",
        "  pairing_strategy = \"greedy\" #@param [\"greedy\", \"complete\"] {type:\"string\"}\n",
        "  #@markdown - `greedy` = pair any taxonomically matching subsets, `complete` = all sequences have to match in one line.\n",
        "\n",
        "\n",
        "  #@markdown #### Sample settings\n",
        "  #@markdown -  enable dropouts and increase number of seeds to sample predictions from uncertainty of the model.\n",
        "  #@markdown -  decrease `max_msa` to increase uncertainity\n",
        "  max_msa = \"auto\" #@param [\"auto\", \"512:1024\", \"256:512\", \"64:128\", \"32:64\", \"16:32\"]\n",
        "  num_seeds = 3 #@param [1,2,3,4,8,16] {type:\"raw\"}\n",
        "  use_dropout = False #@param {type:\"boolean\"}\n",
        "\n",
        "  num_recycles = None if num_recycles == \"auto\" else int(num_recycles)\n",
        "  recycle_early_stop_tolerance = None if recycle_early_stop_tolerance == \"auto\" else float(recycle_early_stop_tolerance)\n",
        "  if max_msa == \"auto\": max_msa = None\n",
        "\n",
        "  #@markdown #### Save settings\n",
        "  save_all = False #@param {type:\"boolean\"}\n",
        "  save_recycles = False #@param {type:\"boolean\"}\n",
        "  save_to_google_drive = True #@param {type:\"boolean\"}\n",
        "  #@markdown -  if the save_to_google_drive option was selected, the result zip will be uploaded to your Google Drive\n",
        "  dpi = 200 #@param {type:\"integer\"}\n",
        "  #@markdown - set dpi for image resolution\n",
        "\n",
        "  if save_to_google_drive:\n",
        "    from pydrive2.drive import GoogleDrive\n",
        "    from pydrive2.auth import GoogleAuth\n",
        "    from google.colab import auth\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    print(\"You are logged into Google Drive and are good to go!\")\n",
        "\n",
        "  #@markdown Don't forget to hit `Runtime` -> `Run all` after updating the form.\n",
        "\n",
        "  #@title Run Prediction\n",
        "  display_images = True #@param {type:\"boolean\"}\n",
        "\n",
        "  import sys\n",
        "  import warnings\n",
        "  warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "  from Bio import BiopythonDeprecationWarning\n",
        "  warnings.simplefilter(action='ignore', category=BiopythonDeprecationWarning)\n",
        "  from pathlib import Path\n",
        "  from colabfold.download import download_alphafold_params, default_data_dir\n",
        "  from colabfold.utils import setup_logging\n",
        "  from colabfold.batch import get_queries, run, set_model_type\n",
        "  from colabfold.plot import plot_msa_v2\n",
        "\n",
        "  import os\n",
        "  import numpy as np\n",
        "  try:\n",
        "    K80_chk = os.popen('nvidia-smi | grep \"Tesla K80\" | wc -l').read()\n",
        "  except:\n",
        "    K80_chk = \"0\"\n",
        "    pass\n",
        "  if \"1\" in K80_chk:\n",
        "    print(\"WARNING: found GPU Tesla K80: limited to total length < 1000\")\n",
        "    if \"TF_FORCE_UNIFIED_MEMORY\" in os.environ:\n",
        "      del os.environ[\"TF_FORCE_UNIFIED_MEMORY\"]\n",
        "    if \"XLA_PYTHON_CLIENT_MEM_FRACTION\" in os.environ:\n",
        "      del os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]\n",
        "\n",
        "  from colabfold.colabfold import plot_protein\n",
        "  from pathlib import Path\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  # For some reason we need that to get pdbfixer to import\n",
        "  if use_amber and f\"/usr/local/lib/python{python_version}/site-packages/\" not in sys.path:\n",
        "      sys.path.insert(0, f\"/usr/local/lib/python{python_version}/site-packages/\")\n",
        "\n",
        "  def input_features_callback(input_features):\n",
        "    if display_images:\n",
        "      plot_msa_v2(input_features)\n",
        "      plt.show()\n",
        "      plt.close()\n",
        "\n",
        "  def prediction_callback(protein_obj, length,\n",
        "                          prediction_result, input_features, mode):\n",
        "    model_name, relaxed = mode\n",
        "    if not relaxed:\n",
        "      if display_images:\n",
        "        fig = plot_protein(protein_obj, Ls=length, dpi=150)\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "  result_dir = jobname\n",
        "  log_filename = os.path.join(jobname,\"log.txt\")\n",
        "  setup_logging(Path(log_filename))\n",
        "\n",
        "  queries, is_complex = get_queries(queries_path)\n",
        "  model_type = set_model_type(is_complex, model_type)\n",
        "\n",
        "  if \"multimer\" in model_type and max_msa is not None:\n",
        "    use_cluster_profile = False\n",
        "  else:\n",
        "    use_cluster_profile = True\n",
        "\n",
        "\n",
        "  try:\n",
        "    download_alphafold_params(model_type, Path(\".\"))\n",
        "    results = run(\n",
        "        queries=queries,\n",
        "        result_dir=result_dir,\n",
        "        use_templates=use_templates,\n",
        "        custom_template_path=custom_template_path,\n",
        "        num_relax=num_relax,\n",
        "        msa_mode=msa_mode,\n",
        "        model_type=model_type,\n",
        "        num_models=5,\n",
        "        num_recycles=num_recycles,\n",
        "        relax_max_iterations=relax_max_iterations,\n",
        "        recycle_early_stop_tolerance=recycle_early_stop_tolerance,\n",
        "        num_seeds=num_seeds,\n",
        "        use_dropout=use_dropout,\n",
        "        model_order=[1,2,3,4,5],\n",
        "        is_complex=is_complex,\n",
        "        data_dir=Path(\".\"),\n",
        "        keep_existing_results=False,\n",
        "        rank_by=\"auto\",\n",
        "        pair_mode=pair_mode,\n",
        "        pairing_strategy=pairing_strategy,\n",
        "        stop_at_score=float(100),\n",
        "        prediction_callback=prediction_callback,\n",
        "        dpi=dpi,\n",
        "        zip_results=False,\n",
        "        save_all=save_all,\n",
        "        max_msa=max_msa,\n",
        "        use_cluster_profile=use_cluster_profile,\n",
        "        input_features_callback=input_features_callback,\n",
        "        save_recycles=save_recycles,\n",
        "        user_agent=\"colabfold/google-colab-main\",\n",
        "    )\n",
        "  except Exception as e:\n",
        "     print(f\"Prediction failed with error: {e}\")\n",
        "     return False\n",
        "\n",
        "  # Zip the results\n",
        "  results_zip = f\"{jobname}.result.zip\"\n",
        "  zip_cmd = f\"zip -r {results_zip} {jobname}\"\n",
        "  if os.system(zip_cmd) != 0:\n",
        "    print(\"Zipping results failed.\")\n",
        "    return False\n",
        "\n",
        "  # Check if ZIP was successfully created\n",
        "  if not os.path.isfile(results_zip):\n",
        "    print(\"Results ZIP not found, prediction might not have completed successfully.\")\n",
        "    return False\n",
        "\n",
        "  #@title Package and download results\n",
        "  #@markdown If you are having issues downloading the result archive, try disabling your adblocker and run this cell again. If that fails click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\" (see [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\n",
        "\n",
        "  if msa_mode == \"custom\":\n",
        "    print(\"Don't forget to cite your custom MSA generation method.\")\n",
        "\n",
        "  if save_to_google_drive == True and drive:\n",
        "    folder_id = get_folder_id_from_path(drive, result_directory)\n",
        "    file_metadata = {\n",
        "        'title': f\"{jobname}.result.zip\",\n",
        "        'parents': [{'id': folder_id}]\n",
        "    }\n",
        "    uploaded = drive.CreateFile(file_metadata)\n",
        "    uploaded.SetContentFile(f\"{jobname}.result.zip\")\n",
        "    try:\n",
        "      uploaded.Upload()\n",
        "      print(f\"Uploaded {jobname}.result.zip to Google Drive in folder '{result_directory}' with ID {uploaded.get('id')}\")\n",
        "    except Exception as e:\n",
        "      print(f\"Upload to Google Drive failed with error: {e}\")\n",
        "      return False\n",
        "\n",
        "  # If we reach until here, everything completed successfully\n",
        "  return True\n",
        "\n",
        "\n",
        "# Create 'done' directory inside fasta_directory\n",
        "fasta_done_directory = os.path.join(fasta_directory, 'done')\n",
        "os.makedirs(fasta_done_directory, exist_ok=True)\n",
        "\n",
        "# Loop over FASTA files and run predictions\n",
        "for fasta_file in os.listdir(fasta_directory):\n",
        "    if fasta_file.endswith('.fasta'):\n",
        "        fasta_path = os.path.join(fasta_directory, fasta_file)\n",
        "\n",
        "        # Parse the FASTA file to extract sequences\n",
        "        for record in SeqIO.parse(fasta_path, \"fasta\"):\n",
        "            peptide = str(record.seq).strip()\n",
        "            jobname = os.path.splitext(fasta_file)[0]  # Use the FASTA file name (without extension) as the job name\n",
        "\n",
        "            print(f\"Processing {fasta_file}: Peptide = {peptide}\")\n",
        "\n",
        "            # Run prediction with the peptide sequence and the correct .a3m file\n",
        "            success = run_prediction(peptide, jobname)\n",
        "\n",
        "        # Move the FASTA file only if the prediction was successful\n",
        "        if success:\n",
        "          shutil.move(fasta_path, os.path.join(fasta_done_directory, fasta_file))\n",
        "        else:\n",
        "           print(f\"Prediction for {fasta_file} did not complete successfully. Not moving the file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#@title Install dependencies\n",
        "%%time\n",
        "import os\n",
        "USE_AMBER = use_amber\n",
        "USE_TEMPLATES = use_templates\n",
        "PYTHON_VERSION = python_version\n",
        "\n",
        "if not os.path.isfile(\"COLABFOLD_READY\"):\n",
        "  print(\"installing colabfold...\")\n",
        "  os.system(\"pip install -q --no-warn-conflicts 'colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold'\")\n",
        "  if os.environ.get('TPU_NAME', False) != False:\n",
        "    os.system(\"pip uninstall -y jax jaxlib\")\n",
        "    os.system(\"pip install --no-warn-conflicts --upgrade dm-haiku==0.0.10 'jax[cuda12_pip]'==0.3.25 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\")\n",
        "  # hack to fix TF crash\n",
        "  os.system(\"rm -f /usr/local/lib/python3.*/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so\")\n",
        "  os.system(\"touch COLABFOLD_READY\")\n",
        "\n",
        "if USE_AMBER or USE_TEMPLATES:\n",
        "  if not os.path.isfile(\"CONDA_READY\"):\n",
        "    print(\"installing conda...\")\n",
        "    os.system(\"wget -qnc https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\")\n",
        "    os.system(\"bash Miniforge3-Linux-x86_64.sh -bfp /usr/local\")\n",
        "    os.system(\"mamba config --set auto_update_conda false\")\n",
        "    os.system(\"touch CONDA_READY\")\n",
        "\n",
        "if USE_TEMPLATES and not os.path.isfile(\"HH_READY\") and USE_AMBER and not os.path.isfile(\"AMBER_READY\"):\n",
        "  print(\"installing hhsuite and amber...\")\n",
        "  os.system(f\"mamba install -y -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 openmm=8.2.0 python='{PYTHON_VERSION}' pdbfixer\")\n",
        "  os.system(\"touch HH_READY\")\n",
        "  os.system(\"touch AMBER_READY\")\n",
        "else:\n",
        "  if USE_TEMPLATES and not os.path.isfile(\"HH_READY\"):\n",
        "    print(\"installing hhsuite...\")\n",
        "    os.system(f\"mamba install -y -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python='{PYTHON_VERSION}'\")\n",
        "    os.system(\"touch HH_READY\")\n",
        "  if USE_AMBER and not os.path.isfile(\"AMBER_READY\"):\n",
        "    print(\"installing amber...\")\n",
        "    os.system(f\"mamba install -y -c conda-forge openmm=8.2.0 python='{PYTHON_VERSION}' pdbfixer\")\n",
        "    os.system(\"touch AMBER_READY\")"
      ],
      "metadata": {
        "id": "AzIKiDiCaHAn"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}